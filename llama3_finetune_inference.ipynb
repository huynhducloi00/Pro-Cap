{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9584d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.5864217281341553\n",
      "2 0.0001590251922607422\n",
      "3 4.8160552978515625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 20:32:32.724045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733279552.844690 3179527 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733279552.848383 3179527 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 8.459800720214844\n"
     ]
    }
   ],
   "source": [
    "from utils import set_env\n",
    "import time\n",
    "set_env()\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import pyarrow as pa\n",
    "i1=time.time()\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "i2=time.time()\n",
    "print('1', i2-i1)\n",
    "from datasets import load_dataset\n",
    "i3=time.time()\n",
    "print('2',i3-i2)\n",
    "import torch\n",
    "i4=time.time()\n",
    "print('3', i4-i3)\n",
    "\n",
    "from trl import SFTTrainer\n",
    "i5=time.time()\n",
    "print('4',i5-i4)\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34ccc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model_original = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True, \n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b422e214-977a-4c45-9d66-b6a698c546eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_name = \"scooterman/guanaco-llama3-1k\"\n",
    "train, test= torch.load('codes/src/trainset_llm.pkl', weights_only=True), torch.load('codes/src/testset_llm.pkl', weights_only=True)\n",
    "for i in range(len(train)):\n",
    "    train[i]['prompt_all_text']=f\"{train[i]['prompt_all_text']} {'good' if train[i]['label']==0 else 'bad'}\"\n",
    "train=Dataset(pa.Table.from_pylist([{'text':x['prompt_all_text']} for x in train]))\n",
    "# test=Dataset(pa.Table.from_pylist([{'text':x['prompt_all_text']} for x in test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b0c17-77af-4328-889a-d418d0814101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory where the results and checkpoint are stored\n",
    "import copy\n",
    "\n",
    "\n",
    "output_dir = \"./results\"\n",
    "max_grad_norm = 0.3\n",
    "learning_rate = 2e-4\n",
    "weight_decay = 0.001\n",
    "optim = \"paged_adamw_32bit\"\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 100\n",
    "logging_steps = 5\n",
    "training_arguments = SFTConfig(\n",
    "    max_seq_length=1024,\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=optim,\n",
    "    save_steps=100,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    bf16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    dataset_text_field=\"text\",\n",
    "    report_to=None\n",
    ")\n",
    "model=copy.deepcopy(model_original)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c25576fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task='text-generation', model=model, tokenizer=tokenizer,\n",
    "    stop_strings=[\"\\n\",'.'],max_new_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395463ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [00:24<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "correct=0\n",
    "res1=[]\n",
    "for i in trange(len(test)):\n",
    "    res=pipe(test[i]['prompt_all_text'], tokenizer=tokenizer)[0]['generated_text']\n",
    "    res_1=res[len(test[i]['prompt_all_text']):].strip()\n",
    "    res1.append(res_1)\n",
    "    guess=0 if res_1=='good' else 1\n",
    "    correct+=guess==test[i]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e452b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    230\n",
       "bad     124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.Series(res1).apply(lambda x:x.strip()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "512002a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9944)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
